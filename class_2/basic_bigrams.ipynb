{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\rober/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6d069a304959>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTreebankWordTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msentence_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/english.pickle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtreebank_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTreebankWordTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 836\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\rober/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rober\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "from nltk.util import bigrams \n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# set this to the full path of the class files\n",
    "dir_base = \"/f18_ds_nlp/class_2/\"\n",
    "\n",
    "def read_file_and_tokenize(filename):\n",
    "    input_file = open(dir_base + \"data/\" + filename , encoding='utf-8').read()\n",
    "    punkt_sentences = sentence_tokenizer.tokenize(input_file)\n",
    "    sentences_words = [treebank_tokenizer.tokenize(sentence) for sentence in punkt_sentences]\n",
    "    return sentences_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Smoke', 'filled', 'the', 'air', 'as', 'multiple', 'fire', 'departments', 'battled', 'a', 'grass', 'fire', 'Monday', 'north', 'of', 'Henry', '.'], ['A', 'large', 'amount', 'of', 'smoke', 'was', 'reported', 'at', 'about', '3:35', 'p.m.', ',', 'about', 'six', 'miles', 'north', 'of', 'Henry', ',', 'Morrill', 'Fire', 'Chief', 'Matt', 'Hinman', 'said', '.'], ['Firefighters', 'from', 'Mitchell', ',', 'Morrill', ',', 'Lyman', ',', 'Torrington', ',', 'Scottsbluff', 'Rural', ',', 'Scottsbluff', 'and', 'Gering', 'were', 'called', 'out', 'to', 'respond', 'to', 'the', 'fire', '.'], ['Firefighters', 'from', 'Yoder', 'and', 'Lingle', ',', 'Wyoming', ',', 'fire', 'departments', ',', 'as', 'well', 'as', 'Hot', 'Springs', ',', 'South', 'Dakota', ',', 'have', 'also', 'been', 'called', 'to', 'assist', '.'], ['Hinman', 'estimated', '50', 'to', '60', 'firefighters', 'have', 'responded', 'to', 'battle', 'the', 'fire', '.'], ['“', 'Right', 'now', ',', 'a', 'wild', 'estimate', 'would', 'be', '200-300', 'acres', ',', '”', 'are', 'burning', ',', 'Hinman', 'said', 'at', 'about', '6', 'p.m.', ',', '“', 'One', 'firefighter', ',', 'Mike', 'Kindred', ',', 'of', 'Lyman', 'Volunteer', 'Fire', ',', 'said', 'he', 'had', 'been', 'on', 'the', 'front', 'lines', 'and', 'called', 'the', 'fire', '“', 'pretty', 'rugged.', '”', 'He', 'said', 'it', 'is', 'smokey', 'and', 'firefighters', 'can', '’', 't', 'see', 'much', 'and', 'are', 'battling', 'the', 'fire', 'on', 'rough', ',', 'sandy', 'terrain', '.'], ['The', 'goal', ',', 'Hinman', 'said', ',', 'is', 'to', '“', 'hold', 'the', 'fire', 'lines', ',', 'hope', 'the', 'winds', 'die', 'down', 'and', 'have', 'the', 'fire', 'contained', 'by', 'dark.', '”', 'Winds', 'were', 'averaging', 'around', '30', 'miles', 'per', 'hour', '.']]\n",
      "[('Smoke', 'filled'), ('filled', 'the'), ('the', 'air'), ('air', 'as'), ('as', 'multiple'), ('multiple', 'fire'), ('fire', 'departments'), ('departments', 'battled'), ('battled', 'a'), ('a', 'grass'), ('grass', 'fire'), ('fire', 'Monday'), ('Monday', 'north'), ('north', 'of'), ('of', 'Henry'), ('Henry', '.'), ('.', 'A'), ('A', 'large'), ('large', 'amount'), ('amount', 'of'), ('of', 'smoke'), ('smoke', 'was'), ('was', 'reported'), ('reported', 'at'), ('at', 'about'), ('about', '3:35'), ('3:35', 'p.m.'), ('p.m.', ','), (',', 'about'), ('about', 'six'), ('six', 'miles'), ('miles', 'north'), ('north', 'of'), ('of', 'Henry'), ('Henry', ','), (',', 'Morrill'), ('Morrill', 'Fire'), ('Fire', 'Chief'), ('Chief', 'Matt'), ('Matt', 'Hinman'), ('Hinman', 'said'), ('said', '.'), ('.', 'Firefighters'), ('Firefighters', 'from'), ('from', 'Mitchell'), ('Mitchell', ','), (',', 'Morrill'), ('Morrill', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'Torrington'), ('Torrington', ','), (',', 'Scottsbluff'), ('Scottsbluff', 'Rural'), ('Rural', ','), (',', 'Scottsbluff'), ('Scottsbluff', 'and'), ('and', 'Gering'), ('Gering', 'were'), ('were', 'called'), ('called', 'out'), ('out', 'to'), ('to', 'respond'), ('respond', 'to'), ('to', 'the'), ('the', 'fire'), ('fire', '.'), ('.', 'Firefighters'), ('Firefighters', 'from'), ('from', 'Yoder'), ('Yoder', 'and'), ('and', 'Lingle'), ('Lingle', ','), (',', 'Wyoming'), ('Wyoming', ','), (',', 'fire'), ('fire', 'departments'), ('departments', ','), (',', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'Hot'), ('Hot', 'Springs'), ('Springs', ','), (',', 'South'), ('South', 'Dakota'), ('Dakota', ','), (',', 'have'), ('have', 'also'), ('also', 'been'), ('been', 'called'), ('called', 'to'), ('to', 'assist'), ('assist', '.'), ('.', 'Hinman'), ('Hinman', 'estimated'), ('estimated', '50'), ('50', 'to'), ('to', '60'), ('60', 'firefighters'), ('firefighters', 'have'), ('have', 'responded'), ('responded', 'to'), ('to', 'battle'), ('battle', 'the'), ('the', 'fire'), ('fire', '.'), ('.', '“'), ('“', 'Right'), ('Right', 'now'), ('now', ','), (',', 'a'), ('a', 'wild'), ('wild', 'estimate'), ('estimate', 'would'), ('would', 'be'), ('be', '200-300'), ('200-300', 'acres'), ('acres', ','), (',', '”'), ('”', 'are'), ('are', 'burning'), ('burning', ','), (',', 'Hinman'), ('Hinman', 'said'), ('said', 'at'), ('at', 'about'), ('about', '6'), ('6', 'p.m.'), ('p.m.', ','), (',', '“'), ('“', 'One'), ('One', 'firefighter'), ('firefighter', ','), (',', 'Mike'), ('Mike', 'Kindred'), ('Kindred', ','), (',', 'of'), ('of', 'Lyman'), ('Lyman', 'Volunteer'), ('Volunteer', 'Fire'), ('Fire', ','), (',', 'said'), ('said', 'he'), ('he', 'had'), ('had', 'been'), ('been', 'on'), ('on', 'the'), ('the', 'front'), ('front', 'lines'), ('lines', 'and'), ('and', 'called'), ('called', 'the'), ('the', 'fire'), ('fire', '“'), ('“', 'pretty'), ('pretty', 'rugged.'), ('rugged.', '”'), ('”', 'He'), ('He', 'said'), ('said', 'it'), ('it', 'is'), ('is', 'smokey'), ('smokey', 'and'), ('and', 'firefighters'), ('firefighters', 'can'), ('can', '’'), ('’', 't'), ('t', 'see'), ('see', 'much'), ('much', 'and'), ('and', 'are'), ('are', 'battling'), ('battling', 'the'), ('the', 'fire'), ('fire', 'on'), ('on', 'rough'), ('rough', ','), (',', 'sandy'), ('sandy', 'terrain'), ('terrain', '.'), ('.', 'The'), ('The', 'goal'), ('goal', ','), (',', 'Hinman'), ('Hinman', 'said'), ('said', ','), (',', 'is'), ('is', 'to'), ('to', '“'), ('“', 'hold'), ('hold', 'the'), ('the', 'fire'), ('fire', 'lines'), ('lines', ','), (',', 'hope'), ('hope', 'the'), ('the', 'winds'), ('winds', 'die'), ('die', 'down'), ('down', 'and'), ('and', 'have'), ('have', 'the'), ('the', 'fire'), ('fire', 'contained'), ('contained', 'by'), ('by', 'dark.'), ('dark.', '”'), ('”', 'Winds'), ('Winds', 'were'), ('were', 'averaging'), ('averaging', 'around'), ('around', '30'), ('30', 'miles'), ('miles', 'per'), ('per', 'hour'), ('hour', '.')]\n"
     ]
    }
   ],
   "source": [
    "newswire_tokens = read_file_and_tokenize(\"newswire.txt\")\n",
    "print(newswire_tokens)\n",
    "all_tokens = [word for sentence in newswire_tokens for word in sentence]\n",
    "bigrams = nltk.bigrams(all_tokens)\n",
    "print(list(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoke', 'filled', 'air', 'multiple', 'fire', 'departments', 'battled', 'grass', 'fire', 'Monday', 'north', 'Henry', '.', 'large', 'amount', 'smoke', 'reported', '3:35', 'p.m.', ',', 'six', 'miles', 'north', 'Henry', ',', 'Morrill', 'Fire', 'Chief', 'Matt', 'Hinman', 'said', '.', 'Firefighters', 'Mitchell', ',', 'Morrill', ',', 'Lyman', ',', 'Torrington', ',', 'Scottsbluff', 'Rural', ',', 'Scottsbluff', 'Gering', 'called', 'respond', 'fire', '.', 'Firefighters', 'Yoder', 'Lingle', ',', 'Wyoming', ',', 'fire', 'departments', ',', 'well', 'Hot', 'Springs', ',', 'South', 'Dakota', ',', 'also', 'called', 'assist', '.', 'Hinman', 'estimated', '50', '60', 'firefighters', 'responded', 'battle', 'fire', '.', '“', 'Right', ',', 'wild', 'estimate', 'would', '200-300', 'acres', ',', '”', 'burning', ',', 'Hinman', 'said', '6', 'p.m.', ',', '“', 'One', 'firefighter', ',', 'Mike', 'Kindred', ',', 'Lyman', 'Volunteer', 'Fire', ',', 'said', 'front', 'lines', 'called', 'fire', '“', 'pretty', 'rugged.', '”', 'said', 'smokey', 'firefighters', '’', 'see', 'much', 'battling', 'fire', 'rough', ',', 'sandy', 'terrain', '.', 'goal', ',', 'Hinman', 'said', ',', '“', 'hold', 'fire', 'lines', ',', 'hope', 'winds', 'die', 'fire', 'contained', 'dark.', '”', 'Winds', 'averaging', 'around', '30', 'miles', 'per', 'hour', '.']\n",
      "[('Smoke', 'filled'), ('filled', 'air'), ('air', 'multiple'), ('multiple', 'fire'), ('fire', 'departments'), ('departments', 'battled'), ('battled', 'grass'), ('grass', 'fire'), ('fire', 'Monday'), ('Monday', 'north'), ('north', 'Henry'), ('Henry', '.'), ('.', 'large'), ('large', 'amount'), ('amount', 'smoke'), ('smoke', 'reported'), ('reported', '3:35'), ('3:35', 'p.m.'), ('p.m.', ','), (',', 'six'), ('six', 'miles'), ('miles', 'north'), ('north', 'Henry'), ('Henry', ','), (',', 'Morrill'), ('Morrill', 'Fire'), ('Fire', 'Chief'), ('Chief', 'Matt'), ('Matt', 'Hinman'), ('Hinman', 'said'), ('said', '.'), ('.', 'Firefighters'), ('Firefighters', 'Mitchell'), ('Mitchell', ','), (',', 'Morrill'), ('Morrill', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'Torrington'), ('Torrington', ','), (',', 'Scottsbluff'), ('Scottsbluff', 'Rural'), ('Rural', ','), (',', 'Scottsbluff'), ('Scottsbluff', 'Gering'), ('Gering', 'called'), ('called', 'respond'), ('respond', 'fire'), ('fire', '.'), ('.', 'Firefighters'), ('Firefighters', 'Yoder'), ('Yoder', 'Lingle'), ('Lingle', ','), (',', 'Wyoming'), ('Wyoming', ','), (',', 'fire'), ('fire', 'departments'), ('departments', ','), (',', 'well'), ('well', 'Hot'), ('Hot', 'Springs'), ('Springs', ','), (',', 'South'), ('South', 'Dakota'), ('Dakota', ','), (',', 'also'), ('also', 'called'), ('called', 'assist'), ('assist', '.'), ('.', 'Hinman'), ('Hinman', 'estimated'), ('estimated', '50'), ('50', '60'), ('60', 'firefighters'), ('firefighters', 'responded'), ('responded', 'battle'), ('battle', 'fire'), ('fire', '.'), ('.', '“'), ('“', 'Right'), ('Right', ','), (',', 'wild'), ('wild', 'estimate'), ('estimate', 'would'), ('would', '200-300'), ('200-300', 'acres'), ('acres', ','), (',', '”'), ('”', 'burning'), ('burning', ','), (',', 'Hinman'), ('Hinman', 'said'), ('said', '6'), ('6', 'p.m.'), ('p.m.', ','), (',', '“'), ('“', 'One'), ('One', 'firefighter'), ('firefighter', ','), (',', 'Mike'), ('Mike', 'Kindred'), ('Kindred', ','), (',', 'Lyman'), ('Lyman', 'Volunteer'), ('Volunteer', 'Fire'), ('Fire', ','), (',', 'said'), ('said', 'front'), ('front', 'lines'), ('lines', 'called'), ('called', 'fire'), ('fire', '“'), ('“', 'pretty'), ('pretty', 'rugged.'), ('rugged.', '”'), ('”', 'said'), ('said', 'smokey'), ('smokey', 'firefighters'), ('firefighters', '’'), ('’', 'see'), ('see', 'much'), ('much', 'battling'), ('battling', 'fire'), ('fire', 'rough'), ('rough', ','), (',', 'sandy'), ('sandy', 'terrain'), ('terrain', '.'), ('.', 'goal'), ('goal', ','), (',', 'Hinman'), ('Hinman', 'said'), ('said', ','), (',', '“'), ('“', 'hold'), ('hold', 'fire'), ('fire', 'lines'), ('lines', ','), (',', 'hope'), ('hope', 'winds'), ('winds', 'die'), ('die', 'fire'), ('fire', 'contained'), ('contained', 'dark.'), ('dark.', '”'), ('”', 'Winds'), ('Winds', 'averaging'), ('averaging', 'around'), ('around', '30'), ('30', 'miles'), ('miles', 'per'), ('per', 'hour'), ('hour', '.')]\n"
     ]
    }
   ],
   "source": [
    "all_tokens = [word for sentence in newswire_tokens for word in sentence]\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "content = [w for w in all_tokens if w.lower() not in stop_words]\n",
    "print(content)\n",
    "bigrams = nltk.bigrams(content)\n",
    "print(list(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_tokenize_remove_stopwords(filename):\n",
    "    file_tokens = read_file_and_tokenize(filename)\n",
    "    all_tokens = [word for sentence in file_tokens for word in sentence]\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in all_tokens if w.lower() not in stop_words]\n",
    "    bigrams = nltk.bigrams(content)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Hinman', 'said'), (',', 'Hinman'), ('”', 'burning'), ('“', 'Right'), (',', 'wild'), ('said', '6'), ('.', '“'), ('200-300', 'acres'), ('estimate', 'would'), ('burning', ','), ('Right', ','), ('p.m.', ','), ('wild', 'estimate'), (',', '”'), ('acres', ','), (',', '“'), ('would', '200-300'), ('6', 'p.m.')}\n",
      "..found 18\n"
     ]
    }
   ],
   "source": [
    "newswire_bigrams = load_file_tokenize_remove_stopwords(\"newswire.txt\")\n",
    "newswire_frankenstein_bigrams = load_file_tokenize_remove_stopwords(\"newswire_frankenstein.txt\")\n",
    "\n",
    "ng1=set(newswire_bigrams)\n",
    "ng2=set(newswire_frankenstein_bigrams)\n",
    "match=set.intersection(ng1,ng2)\n",
    "print(match)\n",
    "print('..found {}'.format(len(match)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'fire'), ('Firefighters', 'from'), ('Hinman', 'said'), ('at', 'about'), ('north', 'of')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "newswire_tokens = read_file_and_tokenize(\"newswire.txt\")\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "all_tokens = [word for sentence in newswire_tokens for word in sentence]\n",
    "finder = BigramCollocationFinder.from_words(all_tokens, window_size = 2)\n",
    "finder.apply_freq_filter(1)\n",
    "\n",
    "colls = finder.nbest(bigram_measures.likelihood_ratio, 5)\n",
    "\n",
    "print(colls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('north', 'Henry'), ('Hinman', 'said'), ('.', 'Firefighters'), ('200-300', 'acres'), ('50', '60')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "newswire_tokens = read_file_and_tokenize(\"newswire.txt\")\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "all_tokens = [word for sentence in newswire_tokens for word in sentence]\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "content = [w for w in all_tokens if w.lower() not in stop_words]\n",
    "    \n",
    "finder = BigramCollocationFinder.from_words(content, window_size = 2)\n",
    "finder.apply_freq_filter(1)\n",
    "\n",
    "colls = finder.nbest(bigram_measures.likelihood_ratio, 5)\n",
    "\n",
    "print(colls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
